name: Provision Environment

on:
  workflow_dispatch:
    inputs:
      template:
        description: "Infrastructure template"
        required: true
        type: choice
        options:
          - api-service
          - api-database
          - scheduled-worker
      environment_name:
        description: "Unique environment name (e.g. my-app-staging)"
        required: true
        type: string
      owner:
        description: "Owner email"
        required: true
        type: string
      ttl:
        description: "Time-to-live (e.g. 7d, 24h)"
        required: false
        type: string
        default: "7d"
      schedule_expression:
        description: "Schedule expression (scheduled-worker only)"
        required: false
        type: string
        default: ""
      s3_bucket_arn:
        description: "S3 bucket ARN (scheduled-worker only)"
        required: false
        type: string
        default: ""
      acm_certificate_arn:
        description: "ACM certificate ARN for HTTPS"
        required: false
        type: string
        default: ""
      route53_zone_id:
        description: "Route 53 zone ID for DNS record"
        required: false
        type: string
        default: ""
      preview_domain:
        description: "Base domain for preview environments (e.g. preview.anersarid.com)"
        required: false
        type: string
        default: ""
      container_image:
        description: "Container image URI (e.g. nginx:alpine or ECR URI)"
        required: false
        type: string
        default: "nginx:alpine"
      container_port:
        description: "Container port"
        required: false
        type: string
        default: "80"
      cpu:
        description: "CPU units for Fargate task (256, 512, 1024, 2048, 4096)"
        required: false
        type: string
        default: "256"
      memory:
        description: "Memory in MiB for Fargate task"
        required: false
        type: string
        default: "512"
      log_retention_days:
        description: "CloudWatch log retention in days (1, 3, 5, 7, 14, 30)"
        required: false
        type: string
        default: "3"
      environment_variables:
        description: "JSON-encoded map of environment variables"
        required: false
        type: string
        default: "{}"
      secret_variables:
        description: "JSON-encoded map of Secrets Manager ARN references"
        required: false
        type: string
        default: "{}"
      use_shared_networking:
        description: "Use shared VPC instead of per-environment VPC"
        required: false
        type: boolean
        default: false

  workflow_call:
    inputs:
      template:
        description: "Infrastructure template"
        required: true
        type: string
      environment_name:
        description: "Unique environment name"
        required: true
        type: string
      owner:
        description: "Owner email"
        required: true
        type: string
      ttl:
        description: "Time-to-live (e.g. 7d, 24h)"
        required: false
        type: string
        default: "7d"
      schedule_expression:
        description: "Schedule expression (scheduled-worker only)"
        required: false
        type: string
        default: ""
      s3_bucket_arn:
        description: "S3 bucket ARN (scheduled-worker only)"
        required: false
        type: string
        default: ""
      acm_certificate_arn:
        description: "ACM certificate ARN for HTTPS"
        required: false
        type: string
        default: ""
      route53_zone_id:
        description: "Route 53 zone ID for DNS record"
        required: false
        type: string
        default: ""
      preview_domain:
        description: "Base domain for preview environments (e.g. preview.anersarid.com)"
        required: false
        type: string
        default: ""
      container_image:
        description: "Container image URI (e.g. nginx:alpine or ECR URI)"
        required: false
        type: string
        default: "nginx:alpine"
      container_port:
        description: "Container port"
        required: false
        type: string
        default: "80"
      cpu:
        description: "CPU units for Fargate task (256, 512, 1024, 2048, 4096)"
        required: false
        type: string
        default: "256"
      memory:
        description: "Memory in MiB for Fargate task"
        required: false
        type: string
        default: "512"
      log_retention_days:
        description: "CloudWatch log retention in days (1, 3, 5, 7, 14, 30)"
        required: false
        type: string
        default: "3"
      environment_variables:
        description: "JSON-encoded map of environment variables"
        required: false
        type: string
        default: "{}"
      secret_variables:
        description: "JSON-encoded map of Secrets Manager ARN references"
        required: false
        type: string
        default: "{}"
      use_shared_networking:
        description: "Use shared VPC instead of per-environment VPC"
        required: false
        type: string
        default: "false"

permissions:
  id-token: write
  contents: read

env:
  STATE_BUCKET: ${{ vars.STATE_BUCKET }}
  AWS_REGION: ${{ vars.AWS_REGION }}
  LOCK_TABLE: ${{ vars.LOCK_TABLE }}

jobs:
  provision:
    name: Provision ${{ inputs.template }} / ${{ inputs.environment_name }}
    runs-on: ubuntu-latest
    environment: production

    steps:
      - name: Validate inputs
        run: |
          set -euo pipefail

          # --- environment_name: lowercase alphanumeric + hyphens, 2-32 chars ---
          ENV_NAME="${{ inputs.environment_name }}"
          if [[ ! "$ENV_NAME" =~ ^[a-z0-9][a-z0-9-]{0,30}[a-z0-9]$ ]] && [[ ! "$ENV_NAME" =~ ^[a-z0-9]{2}$ ]]; then
            echo "::error::Invalid environment_name '${ENV_NAME}'. Must be 2-32 chars, lowercase alphanumeric and hyphens, cannot start/end with a hyphen."
            exit 1
          fi

          # --- template: must be a known value ---
          TEMPLATE="${{ inputs.template }}"
          if [[ "$TEMPLATE" != "api-service" && "$TEMPLATE" != "api-database" && "$TEMPLATE" != "scheduled-worker" ]]; then
            echo "::error::Invalid template '${TEMPLATE}'. Must be one of: api-service, api-database, scheduled-worker."
            exit 1
          fi

          # --- ttl: number followed by d or h ---
          TTL="${{ inputs.ttl }}"
          if [[ ! "$TTL" =~ ^[0-9]+[dh]$ ]]; then
            echo "::error::Invalid TTL '${TTL}'. Must be a number followed by d (days) or h (hours). Example: 7d, 24h."
            exit 1
          fi

          # --- container_port: valid port number ---
          PORT="${{ inputs.container_port }}"
          if [[ -n "$PORT" ]] && ! [[ "$PORT" =~ ^[0-9]+$ ]] || (( PORT < 1 || PORT > 65535 )); then
            echo "::error::Invalid container_port '${PORT}'. Must be a number between 1 and 65535."
            exit 1
          fi

          # --- schedule_expression: if template is scheduled-worker, must be provided ---
          SCHEDULE="${{ inputs.schedule_expression }}"
          if [[ "$TEMPLATE" == "scheduled-worker" && -z "$SCHEDULE" ]]; then
            echo "::error::schedule_expression is required for the scheduled-worker template."
            exit 1
          fi

          # --- environment_variables / secret_variables: must be valid JSON objects ---
          ENV_VARS='${{ inputs.environment_variables }}'
          if [[ -n "$ENV_VARS" && "$ENV_VARS" != "{}" ]]; then
            if ! echo "$ENV_VARS" | jq -e 'type == "object"' > /dev/null 2>&1; then
              echo "::error::environment_variables must be a valid JSON object. Got: ${ENV_VARS}"
              exit 1
            fi
          fi

          SECRET_VARS='${{ inputs.secret_variables }}'
          if [[ -n "$SECRET_VARS" && "$SECRET_VARS" != "{}" ]]; then
            if ! echo "$SECRET_VARS" | jq -e 'type == "object"' > /dev/null 2>&1; then
              echo "::error::secret_variables must be a valid JSON object. Got: ${SECRET_VARS}"
              exit 1
            fi
          fi

          echo "All inputs validated successfully."

      - name: Checkout infrastructure code
        uses: actions/checkout@v4
        with:
          repository: AnerSarid/mini-idp
          ref: main

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install OpenTofu
        uses: opentofu/setup-opentofu@v1
        with:
          tofu_wrapper: false

      - name: Compute timestamps and generate tfvars
        id: tfvars
        run: |
          set -euo pipefail

          CREATED_AT=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          TTL_RAW="${{ inputs.ttl }}"
          if [[ "$TTL_RAW" =~ ^([0-9]+)d$ ]]; then
            TTL_SECONDS=$(( ${BASH_REMATCH[1]} * 86400 ))
          elif [[ "$TTL_RAW" =~ ^([0-9]+)h$ ]]; then
            TTL_SECONDS=$(( ${BASH_REMATCH[1]} * 3600 ))
          else
            echo "::error::Invalid TTL format. Use <number>d or <number>h."
            exit 1
          fi

          EXPIRES_AT=$(date -u -d "${CREATED_AT} + ${TTL_SECONDS} seconds" +"%Y-%m-%dT%H:%M:%SZ")

          mkdir -p infrastructure/environments
          TFVARS_FILE="infrastructure/environments/${{ inputs.environment_name }}.tfvars.json"

          # Build the tfvars JSON using jq — no heredocs, no sed, no indentation bugs.
          # Start with base variables common to all templates.
          jq -n \
            --arg env_name "${{ inputs.environment_name }}" \
            --arg owner "${{ inputs.owner }}" \
            --arg ttl "${{ inputs.ttl }}" \
            --arg created_at "$CREATED_AT" \
            --arg expires_at "$EXPIRES_AT" \
            '{
              environment_name: $env_name,
              owner: $owner,
              ttl: $ttl,
              created_at: $created_at,
              expires_at: $expires_at
            }' > "$TFVARS_FILE"

          # Template-specific: scheduled-worker
          if [[ "${{ inputs.template }}" == "scheduled-worker" ]]; then
            jq \
              --arg schedule "${{ inputs.schedule_expression }}" \
              --arg s3_arn "${{ inputs.s3_bucket_arn }}" \
              '. + {schedule_expression: $schedule, s3_bucket_arn: $s3_arn}' \
              "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"
          fi

          # DNS and HTTPS (api-service, api-database)
          if [[ "${{ inputs.template }}" == "api-service" || "${{ inputs.template }}" == "api-database" ]]; then
            jq \
              --arg acm "${{ inputs.acm_certificate_arn }}" \
              --arg zone "${{ inputs.route53_zone_id }}" \
              --arg domain "${{ inputs.preview_domain }}" \
              '. + (if $acm != "" then {acm_certificate_arn: $acm} else {} end)
                 + (if $zone != "" then {route53_zone_id: $zone} else {} end)
                 + (if $domain != "" then {preview_domain: $domain} else {} end)' \
              "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"
          fi

          # Container configuration — only include non-default values.
          # Terraform variable defaults handle the rest.
          jq \
            --arg image "${{ inputs.container_image }}" \
            --arg port "${{ inputs.container_port }}" \
            --arg cpu "${{ inputs.cpu }}" \
            --arg memory "${{ inputs.memory }}" \
            --arg log_ret "${{ inputs.log_retention_days }}" \
            '. + (if $image != "" and $image != "nginx:alpine" then {container_image: $image} else {} end)
               + (if $port != "" and $port != "80" then {container_port: ($port | tonumber)} else {} end)
               + (if $cpu != "" and $cpu != "256" then {cpu: ($cpu | tonumber)} else {} end)
               + (if $memory != "" and $memory != "512" then {memory: ($memory | tonumber)} else {} end)
               + (if $log_ret != "" and $log_ret != "3" then {log_retention_days: ($log_ret | tonumber)} else {} end)' \
            "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"

          # Environment variables (already JSON — merge directly)
          ENV_VARS='${{ inputs.environment_variables }}'
          if [[ -n "$ENV_VARS" && "$ENV_VARS" != "{}" ]]; then
            jq --argjson env_vars "$ENV_VARS" '. + {environment_variables: $env_vars}' \
              "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"
          fi

          # Secret variables (already JSON — merge directly)
          SECRET_VARS='${{ inputs.secret_variables }}'
          if [[ -n "$SECRET_VARS" && "$SECRET_VARS" != "{}" ]]; then
            jq --argjson secret_vars "$SECRET_VARS" '. + {secret_variables: $secret_vars}' \
              "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"
          fi

          # Shared networking
          if [[ "${{ inputs.use_shared_networking }}" == "true" ]]; then
            jq --arg bucket "$STATE_BUCKET" \
              '. + {use_shared_networking: true, state_bucket: $bucket}' \
              "$TFVARS_FILE" > "$TFVARS_FILE.tmp" && mv "$TFVARS_FILE.tmp" "$TFVARS_FILE"
          fi

          echo "tfvars_file=${TFVARS_FILE}" >> "$GITHUB_OUTPUT"
          echo "created_at=${CREATED_AT}" >> "$GITHUB_OUTPUT"
          echo "expires_at=${EXPIRES_AT}" >> "$GITHUB_OUTPUT"

      - name: Copy shared base files into template
        run: cp infrastructure/templates/_base/*.tf "infrastructure/templates/${{ inputs.template }}/"

      - name: Tofu init
        working-directory: infrastructure/templates/${{ inputs.template }}
        run: |
          tofu init -input=false \
            -backend-config="bucket=${STATE_BUCKET}" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${LOCK_TABLE}" \
            -backend-config="key=environments/${{ inputs.environment_name }}/terraform.tfstate"

      - name: Tofu plan
        working-directory: infrastructure/templates/${{ inputs.template }}
        run: |
          tofu plan \
            -var-file="${{ github.workspace }}/${{ steps.tfvars.outputs.tfvars_file }}" \
            -out=tfplan \
            -input=false \
            -lock-timeout=5m

      - name: Tofu apply
        working-directory: infrastructure/templates/${{ inputs.template }}
        run: tofu apply -input=false -lock-timeout=5m tfplan

      - name: Upload outputs to S3
        working-directory: infrastructure/templates/${{ inputs.template }}
        run: |
          set -euo pipefail
          tofu output -json > outputs.json
          aws s3 cp outputs.json \
            "s3://${STATE_BUCKET}/environments/${{ inputs.environment_name }}/outputs.json" \
            --content-type "application/json"

      - name: Upload tfvars to S3
        run: |
          set -euo pipefail
          aws s3 cp "${{ steps.tfvars.outputs.tfvars_file }}" \
            "s3://${STATE_BUCKET}/environments/${{ inputs.environment_name }}/tfvars.json" \
            --content-type "application/json"

      - name: Upload metadata to S3
        run: |
          set -euo pipefail
          jq -n \
            --arg name "${{ inputs.environment_name }}" \
            --arg template "${{ inputs.template }}" \
            --arg owner "${{ inputs.owner }}" \
            --arg ttl "${{ inputs.ttl }}" \
            --arg created_at "${{ steps.tfvars.outputs.created_at }}" \
            --arg expires_at "${{ steps.tfvars.outputs.expires_at }}" \
            --arg container_image "${{ inputs.container_image }}" \
            --arg acm_arn "${{ inputs.acm_certificate_arn }}" \
            --arg zone_id "${{ inputs.route53_zone_id }}" \
            --arg domain "${{ inputs.preview_domain }}" \
            --arg shared "${{ inputs.use_shared_networking }}" \
            '{
              name: $name,
              template: $template,
              owner: $owner,
              ttl: $ttl,
              created_at: $created_at,
              expires_at: $expires_at,
              status: "active",
              container_image: $container_image,
              acm_certificate_arn: $acm_arn,
              route53_zone_id: $zone_id,
              preview_domain: $domain,
              use_shared_networking: $shared
            }' > metadata.json
          aws s3 cp metadata.json \
            "s3://${STATE_BUCKET}/environments/${{ inputs.environment_name }}/metadata.json" \
            --content-type "application/json"
